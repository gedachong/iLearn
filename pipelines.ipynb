{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4b2f80-d862-4cea-8093-2f70b5097bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME']=\"/GL8616/HF\"\n",
    "os.environ['HF_HUB_CACHE']=\"/GL8616/HF/HUB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb14fc48-f622-42e4-ab57-732cdf7fc7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://hf-mirror.com/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7660620212554932}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"sentiment-analysis\")\n",
    "pipe(\"今儿合肥真热呀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cfdbbb9-054d-4e25-be18-b3eafc240c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8148192167282104}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"这家店的肉味道一般\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "965fa95f-546f-4ddb-b4a2-92752579b384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7328070998191833},\n",
       " {'label': 'NEGATIVE', 'score': 0.9411410689353943},\n",
       " {'label': 'NEGATIVE', 'score': 0.9046947360038757},\n",
       " {'label': 'POSITIVE', 'score': 0.9998540878295898}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\n",
    "    \"今天天气不好\",\n",
    "    \"不知道怎么测试\",\n",
    "    \"数据质量很好\",\"The quanlity is really good\"]\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "852f5a81-4248-415b-94b1-06dcd0175f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://hf-mirror.com/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task='ner')\n",
    "preds = classifier('Hugging Face is a French company based in New York City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7deb7ce-a514-4038-89e7-cbfaa7d914f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9965166, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9281086, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.97559255, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.998278, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.9985862, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.99826473, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9986085, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b92fae9-96c6-43cf-b609-e7e26b7c862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://hf-mirror.com/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'ORG', 'score': 0.9674639, 'word': 'Hugging Face', 'start': 0, 'end': 12}\n",
      "{'entity_group': 'MISC', 'score': 0.99828726, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity_group': 'LOC', 'score': 0.99896103, 'word': 'New York City', 'start': 42, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\", grouped_entities=True)\n",
    "preds_grp=classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "print(*preds_grp,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d62435e-1397-4baf-b981-4514f130c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://hf-mirror.com/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(task=\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4db8880-c524-4039-9bdc-7cc983878c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9327, start: 30, end: 54, answer: huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31e4f15b-162a-4083-b0cf-0ed346cf8169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"t5-base\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5002bb33-f7a6-4277-b671-e2057d5412a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decode'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0470979-262d-44af-a8a4-42b608e7fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 32, but your input_length is only 7. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ',  ,'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "   我的第一周作业后来是有重新提交过，第一次提交链接有问题\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "759470ff-075b-4ce6-9d82-fe8dbd68acf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at superb/hubert-base-superb-er were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at superb/hubert-base-superb-er and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6234720d-2089-46fe-acd9-a653dbc0ba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da1fa259-138d-470c-bae5-30b77c0ea220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' The latest delivery. 2014, Qirei 153. All cars are painted and painted. The insurance car is coming. Look at the new car. The real leather seat. The city is small, S-U-V. Who wants to buy a car? Not yet.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = transcriber(\"/GL8616/data/mmexport1629685986212.mp4\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8442c8f3-4571-4f15-ad5f-e4301f13d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "whisper_large = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ce6f79b-216c-4289-91dc-19412fe38dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" The latest delivery 14 years Qi Rui Yihu 3 The whole car is two pieces of Huaheng supplementary insurance check next year See if this car is new Real leather seats City small SUV Who wants to be called TC A car that hasn't passed\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = whisper_large(\"/GL8616/data/mmexport1629685986212.mp4\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0ae8bd1-bbc6-4c86-bc4b-db3089f4b3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://hf-mirror.com/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "img_classifier = pipeline(task=\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "692b6000-86fc-4021-b6d6-73a2e310c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2715, 'label': 'minivan'}\n",
      "{'score': 0.155, 'label': 'cab, hack, taxi, taxicab'}\n",
      "{'score': 0.0629, 'label': 'sports car, sport car'}\n",
      "{'score': 0.0616, 'label': 'gas pump, gasoline pump, petrol pump, island dispenser'}\n",
      "{'score': 0.0574, 'label': 'car wheel'}\n"
     ]
    }
   ],
   "source": [
    "preds = img_classifier(\n",
    "    \"/GL8616/data/wx_camera_1627809335895.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d669fe1-7eac-4e80-9005-f6caba8d87d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9312, 'label': 'pug, pug-dog'}\n",
      "{'score': 0.0253, 'label': 'Pekinese, Pekingese, Peke'}\n",
      "{'score': 0.016, 'label': 'Brabancon griffon'}\n",
      "{'score': 0.0083, 'label': 'bull mastiff'}\n",
      "{'score': 0.0016, 'label': 'Shih-Tzu'}\n"
     ]
    }
   ],
   "source": [
    "preds = img_classifier(\n",
    "    \"/GL8616/data/IMG_20230225_121638.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6baa59e3-9475-474b-ae92-2afbe02e2617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 2729413 (https://hf-mirror.com/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "detector = pipeline(task=\"object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92c975bc-5c73-4549-8bf2-a609dc44a989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9985,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 1100, 'ymin': 1, 'xmax': 1891, 'ymax': 509}},\n",
       " {'score': 0.9997,\n",
       "  'label': 'dog',\n",
       "  'box': {'xmin': 1455, 'ymin': 525, 'xmax': 3178, 'ymax': 2973}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"/GL8616/data/IMG_20230225_121638.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
